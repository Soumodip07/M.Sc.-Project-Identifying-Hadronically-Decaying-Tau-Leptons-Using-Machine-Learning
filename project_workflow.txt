============================================
Environment Setup and Project Workflow Notes
============================================

--------------------------------------------
ğŸ”§ Software Environment (Versions Used)
--------------------------------------------

1. MadGraph5_aMC@NLO v3.5.6
   Website: https://launchpad.net/mg5amcnlo

2. Pythia8 v8.3.12
   Website: https://pythia.org

3. FastJet v3.4.3
   Website: https://fastjet.fr

4. Python 3.12.3
   Key packages: numpy, matplotlib, h5py, tqdm, tensorflow (v2.12), scikit-learn

Optional:
- Google Colab for model training and GPU acceleration

--------------------------------------------
ğŸ“¡ Process Generation in MadGraph
--------------------------------------------

1. Hadronically decaying tau jets:
   generate e+ e- > ta+ ta-

2. Quark jet background:
   generate e+ e- > j j
   (where j = u d s c u~ d~ s~ c~)

Commands in MadGraph:
> import model sm  
> generate e+ e- > ta+ ta-  
> output tau_dir  
> launch  

> import model sm  
> generate e+ e- > j j  
> output jj_dir  
> launch  

Each output LHE file is then passed to Pythia8 for hadronization.

--------------------------------------------
ğŸš€ Dataset Construction & Code Structure
--------------------------------------------

We simulate and process:
âœ”ï¸ **3 training datasets** at:  
   - 100 GeV (75k events)  
   - 200 GeV (75k events)  
   - 300 GeV (75k events)  

âœ”ï¸ **7 test datasets** at:  
   - 100, 150, 200, 250, 300, 350, 400 GeV  
   - 100k events each

Jupyter Notebooks 1â€“6 are used for:
- Hadronization (Pythia8 interface)
- Jet clustering with FastJet
- Jet image creation and preprocessing (centering, rotation, normalization)
- Saving full/core jet image datasets (`.npy` files)

Notebook order:
1. 1Tau_hadronize_jetcluster_data.ipynb
2. 2Tau_jetimage_processing.ipynb
3. 3jj_hadronize_jetcluster_data.ipynb
4. 4jj_jetimage_processing.ipynb
5. 5Final_dataset_creation.ipynb
6. 6kinematics_plots.ipynb

--------------------------------------------
ğŸ§  CNN Model Training & Evaluation
--------------------------------------------

CNN models are built and trained on **Google Colab** with GPU support using TensorFlow 2.x.

- Models trained separately on 3 training sets (100, 200, 300 GeV)
- Each trained model is evaluated across all 7 test datasets

CNN notebooks:
- CNN_model1_training.ipynb
- CNN_models_test.ipynb

Metrics computed:
- Accuracy, AUC, Precision, Recall
- ROC curves
- Tau tagging efficiency vs. quark mistag rate vs. $p_T$

--------------------------------------------
ğŸ“ Note on LHE Files
--------------------------------------------

Each center-of-mass energy simulation was performed using separate LHE files from MadGraph.

---
